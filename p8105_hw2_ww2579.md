Homework 2
================
Wenzhao Wu

``` r
library(tidyverse)
```

    ## -- Attaching packages ------------------

    ## v ggplot2 3.3.2     v purrr   0.3.4
    ## v tibble  3.0.3     v dplyr   1.0.2
    ## v tidyr   1.1.2     v stringr 1.4.0
    ## v readr   1.3.1     v forcats 0.5.0

    ## -- Conflicts -- tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
library(dbplyr)
```

    ## 
    ## Attaching package: 'dbplyr'

    ## The following objects are masked from 'package:dplyr':
    ## 
    ##     ident, sql

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>%
  janitor::clean_names() %>%
  drop_na(dumpster) %>%
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data\!

``` r
precip_2018 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2018) %>%
  relocate(year)


precip_2017 = 
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
  ) %>%
  janitor::clean_names() %>%
  drop_na(month) %>%
  mutate(year = 2017) %>%
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018, precip_2017)

left_join(precip_df, month_df, by = "month")
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # ... with 14 more rows

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stroes it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data.

## Problem 2

``` r
nyc_transit_df = 
  read_csv(
    "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(
      Route8 = col_character(),
      Route9 = col_character(),
      Route10 = col_character(),
      Route11 = col_character()
    )) %>%
  janitor::clean_names() %>%
  select(line:entry, vending, ada) %>%
  mutate(
    entry = recode(entry, "YES" = "TRUE", "NO" = "FALSE"),
    entry = as.logical(entry, levels = c("TRUE","FALSE")))

nyc_transit_df
```

    ## # A tibble: 1,868 x 19
    ##    line  station_name station_latitude station_longitu~ route1 route2 route3
    ##    <chr> <chr>                   <dbl>            <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Av~ 25th St                  40.7            -74.0 R      <NA>   <NA>  
    ##  2 4 Av~ 25th St                  40.7            -74.0 R      <NA>   <NA>  
    ##  3 4 Av~ 36th St                  40.7            -74.0 N      R      <NA>  
    ##  4 4 Av~ 36th St                  40.7            -74.0 N      R      <NA>  
    ##  5 4 Av~ 36th St                  40.7            -74.0 N      R      <NA>  
    ##  6 4 Av~ 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  7 4 Av~ 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  8 4 Av~ 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  9 4 Av~ 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ## 10 4 Av~ 53rd St                  40.6            -74.0 R      <NA>   <NA>  
    ## # ... with 1,858 more rows, and 12 more variables: route4 <chr>, route5 <chr>,
    ## #   route6 <chr>, route7 <chr>, route8 <chr>, route9 <chr>, route10 <chr>,
    ## #   route11 <chr>, entrance_type <chr>, entry <lgl>, vending <chr>, ada <lgl>

This dataset contains data about line, stations’ names, geographical
locations and routes served. Also, it includes information of the
entrance type, whether there exists an entry or vending, and whether the
ADA is complied with. By far, I have cleaned up variable names to
lower\_snake\_case, and selected only the columns of variables that I am
interested in.

There are 1868 rows and 19 columns of the resulting dataset. These data
are currently not tidy at all, because for example, some columns could
have been combined together for tidiness.

There are 465 distinct stations shown in the dataset.

In addition, there are 84 distinct stations compliant with ADA.

The number of entrances without vending is 183. Among these entrances,
there are 69 allowing entry. Thus, the proportion of entrances without
vending that allow entry would be 37.704918 %.

Reformatting data.

``` r
nyc_tidy = 
  pivot_longer(
  nyc_transit_df,
  route1:route11,
  names_to = "route_names",
  values_to = "route_numbers",
  names_prefix = "route") %>%
  distinct(station_name, line, route_names, route_numbers, .keep_all = TRUE)
```

For distinct stations, there are 60 serving the A train, of which there
are 17 ADA compliant.

## Problem3

``` r
pols_month = 
  read_csv(
    "./data/pols-month.csv") %>%
  janitor::clean_names()
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

``` r
pols_month =
  separate(pols_month, mon, into = c("year", "month_num", "day")) %>%
  mutate(
    year = as.integer(year),
    month_num = as.integer(month_num),
    day = as.integer(day)) %>%
  select(-prez_gop,-prez_dem,-day) %>%
  pivot_longer(
  gov_gop:rep_dem,
  names_to = "president",
  values_to = "pol")

month_df = 
  tibble(month_num = 1:12,
          month = month.abb)
joina_df = left_join(month_df,pols_month, by = "month_num")
pols_df = select(joina_df, -month_num) %>%
  relocate(year, month)
```

``` r
snp = 
  read_csv(
    "./data/snp.csv") %>%
  janitor::clean_names()
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

``` r
snp =
  separate(snp, date, into = c("month_num", "day","year")) %>%
  mutate(
    year = as.integer(year),
    month_num = as.integer(month_num),
    day = as.integer(day)) %>%
  select(-day)

month_df = 
  tibble(month_num = 1:12,
          month = month.abb)

joinb_df = left_join(month_df,snp, by = "month_num")

snp_df = select(joinb_df,-month_num) %>%
  relocate(year, month)
```

``` r
unemployment = 
  read_csv(
    "./data/unemployment.csv") %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemp") %>%
  janitor::clean_names()
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

Merge 3 datasets.

``` r
snp_pols = 
  left_join(snp_df,pols_df, by = c("year","month"))

all_df = 
  left_join(unemployment, snp_pols, by = c("year","month"))

all_df
```

    ## # A tibble: 4,746 x 6
    ##     year month unemp close president   pol
    ##    <dbl> <chr> <dbl> <dbl> <chr>     <dbl>
    ##  1  1948 Jan     3.4    NA <NA>         NA
    ##  2  1948 Feb     3.8    NA <NA>         NA
    ##  3  1948 Mar     4      NA <NA>         NA
    ##  4  1948 Apr     3.9    NA <NA>         NA
    ##  5  1948 May     3.5    NA <NA>         NA
    ##  6  1948 Jun     3.6    NA <NA>         NA
    ##  7  1948 Jul     3.6    NA <NA>         NA
    ##  8  1948 Aug     3.9    NA <NA>         NA
    ##  9  1948 Sep     3.8    NA <NA>         NA
    ## 10  1948 Oct     3.7    NA <NA>         NA
    ## # ... with 4,736 more rows

The pol\_df dataset contains information about presidents and their
corresponding “pols” integers in each month from 1947 to 2015. I used
function **separate()** to break “mon” into three different variables.
The columns of “prez\_dem”, “prez\_gop” and “day” were removed by using
**select()**. Then other “gop” and “dem” columns were combined by
function **pivot\_longer()**.

The snp\_df includes data of year, month, close, from 1950 to 2015. The
first two datasets were both replaced month numbers with month names by
creating a separate dataframe which was then merged into the dataset
using **left\_join()**.

The third dataset of unemployment has 816 rows and 3 columns. The data
ranges from 1948 to 2015.

The merged dataset with combined information from the previous three
datasets, which contains 4746 rows and 6 columns. Variables includes
year, month, unemp, close, president, pol. The merging is based on the
common columns “year” and “month”, by the function **left\_join**.
